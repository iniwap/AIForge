from typing import Optional, Dict, Any


def get_task_specific_format(task_type: str) -> str:
    """è·å–ä»»åŠ¡ç‰¹å®šçš„è¾“å‡ºæ ¼å¼è¦æ±‚"""
    formats = {
        "web_search": """
# æœç´¢ä»»åŠ¡è¾“å‡ºæ ¼å¼
__result__ = {
    "data": {
        "results": [{"title": "...", "url": "...", "content": "..."}],
        "total_count": int,
        "query": "åŸå§‹æŸ¥è¯¢"
    },
    "status": "success",
    "summary": "æœç´¢å®Œæˆæè¿°",
    "metadata": {"timestamp": "...", "source": "æœç´¢å¼•æ“åç§°"}
}""",
        "data_analysis": """
# æ•°æ®åˆ†æä»»åŠ¡è¾“å‡ºæ ¼å¼
__result__ = {
    "data": {
        "analysis": {"key_findings": "...", "trends": "..."},
        "processed_data": processed_data,
        "summary": {"total_records": int, "key_metrics": {}}
    },
    "status": "success",
    "summary": "åˆ†æå®Œæˆæè¿°",
    "metadata": {"timestamp": "...", "data_source": "..."}
}""",
        "file_processing": """
# æ–‡ä»¶å¤„ç†ä»»åŠ¡è¾“å‡ºæ ¼å¼
__result__ = {
    "data": {
        "processed_files": [{"file": "...", "status": "success", "size": int}],
        "summary": {"total_files": int, "success_count": int, "error_count": int},
        "errors": [{"file": "...", "error": "..."}]
    },
    "status": "success",
    "summary": "æ–‡ä»¶å¤„ç†å®Œæˆæè¿°",
    "metadata": {"timestamp": "...", "operation": "..."}
}""",
        "api_call": """
# APIè°ƒç”¨ä»»åŠ¡è¾“å‡ºæ ¼å¼
__result__ = {
    "data": {
        "response_data": api_response,
        "status_code": int,
        "headers": response_headers,
        "summary": {"success": bool, "response_time": float}
    },
    "status": "success",
    "summary": "APIè°ƒç”¨å®Œæˆæè¿°",
    "metadata": {"endpoint": "...", "timestamp": "..."}
}""",
        "data_fetch": """
# æ•°æ®è·å–ä»»åŠ¡è¾“å‡ºæ ¼å¼
__result__ = {
    "data": {
        "content": "è·å–çš„æ•°æ®å†…å®¹",
        "source": "æ•°æ®æ¥æº",
        "additional_info": {}
    },
    "status": "success",
    "summary": "æ•°æ®è·å–å®Œæˆæè¿°",
    "metadata": {"timestamp": "...", "task_type": "data_fetch"}
}""",
        "web_request": """
# ç½‘é¡µè¯·æ±‚ä»»åŠ¡è¾“å‡ºæ ¼å¼
__result__ = {
    "data": {
        "content": "ç½‘é¡µå†…å®¹",
        "url": "è¯·æ±‚çš„URL",
        "status_code": int,
        "headers": {}
    },
    "status": "success",
    "summary": "ç½‘é¡µè¯·æ±‚å®Œæˆæè¿°",
    "metadata": {"timestamp": "...", "method": "GET/POST"}
}""",
        "automation": """
# è‡ªåŠ¨åŒ–ä»»åŠ¡è¾“å‡ºæ ¼å¼
__result__ = {
    "data": {
        "executed_steps": ["æ­¥éª¤1", "æ­¥éª¤2"],
        "results": {},
        "summary": {"total_steps": int, "success_steps": int}
    },
    "status": "success",
    "summary": "è‡ªåŠ¨åŒ–ä»»åŠ¡å®Œæˆæè¿°",
    "metadata": {"timestamp": "...", "workflow": "..."}
}""",
        "content_generation": """
# å†…å®¹ç”Ÿæˆä»»åŠ¡è¾“å‡ºæ ¼å¼
__result__ = {
    "data": {
        "generated_content": "ç”Ÿæˆçš„å†…å®¹",
        "content_type": "text/html/markdown",
        "word_count": int
    },
    "status": "success",
    "summary": "å†…å®¹ç”Ÿæˆå®Œæˆæè¿°",
    "metadata": {"timestamp": "...", "template": "..."}
}""",
    }

    return formats.get(
        task_type,
        """
# è¾“å‡ºæ ¼å¼è¦æ±‚ï¼š
__result__ = {
    "data": main_result,
    "status": "success/error",
    "summary": "ç»“æœæ‘˜è¦",
    "metadata": {"timestamp": "...", "task_type": "..."}
}""",
    )


def get_base_aiforge_prompt(optimize_tokens: bool = True) -> str:
    """ç”ŸæˆåŸºç¡€çš„AIForgeç³»ç»Ÿæç¤º"""
    # åŸºç¡€ä»£ç ç”Ÿæˆè§„åˆ™
    code_rule = """
- ç”Ÿæˆçš„ä»£ç å¿…é¡»èƒ½åœ¨æ ‡å‡† Python ç¯å¢ƒä¸­ç›´æ¥æ‰§è¡Œ
- ä½¿ç”¨æ ‡å‡† Markdown ä»£ç å—æ ¼å¼ï¼š```python ... ```ï¼Œä¸è¦è¾“å‡ºä»»ä½•è§£é‡Šæ€§æ–‡å­—
- ä½¿ç”¨é¢„è£…åº“ï¼šrequests, BeautifulSoup, pandas, numpy ç­‰
- å®ç°å®Œæ•´çš„é”™è¯¯å¤„ç†å’Œå¼‚å¸¸æ•è·
"""

    if optimize_tokens:
        code_rule += "\n- ç”Ÿæˆæç®€ä»£ç ï¼Œæ— æ³¨é‡Šï¼Œæ— ç©ºè¡Œ\n- ä½¿ç”¨æœ€çŸ­å˜é‡å(a,b,c,dç­‰)"

    # æ„å»ºåŸºç¡€ prompt
    base_prompt = f"""
# AIForgeï¼šPython ä»£ç ç”Ÿæˆå’Œæ‰§è¡ŒåŠ©æ‰‹

# ä»£ç ç”Ÿæˆè§„èŒƒ
{code_rule}

# æ‰§è¡Œè§„èŒƒ
æ‰§è¡Œä»£ç ï¼Œå¹¶å°†æ‰§è¡Œç»“æœèµ‹å€¼ç»™ __result__

"""
    return base_prompt


def get_enhanced_aiforge_prompt(
    optimize_tokens: bool = True,
    task_type: Optional[str] = None,
    parameters: Optional[Dict[str, Any]] = None,
) -> str:
    """ç”Ÿæˆå¢å¼ºçš„ç³»ç»Ÿæç¤º"""

    base_prompt = get_base_aiforge_prompt(optimize_tokens)

    # æ™ºèƒ½å‚æ•°åŒ–æ‰§è¡ŒæŒ‡å¯¼
    execution_guidance = ""
    if parameters:
        # åˆ†æå‚æ•°ç»“æ„ï¼Œç”Ÿæˆæ™ºèƒ½çš„å‡½æ•°å®šä¹‰
        param_analysis = _analyze_parameters_for_execution(parameters)

        execution_guidance = f"""
## ğŸ”§ æ™ºèƒ½å‚æ•°åŒ–æ‰§è¡ŒæŒ‡å¯¼

åŸºäºä»»åŠ¡åˆ†æï¼Œç”Ÿæˆä»¥ä¸‹å‚æ•°åŒ–å‡½æ•°ï¼š

def execute_task({param_analysis['signature']}):
    '''
    {param_analysis['docstring']}
    '''
    # ä½¿ç”¨ä¼ å…¥çš„å‚æ•°å®Œæˆä»»åŠ¡
    # å®ç°é€»è¾‘åº”è¯¥åŸºäºå‚æ•°çš„å®é™…å«ä¹‰å’Œä»»åŠ¡éœ€æ±‚
    return result_data

# å‚æ•°è¯´æ˜ï¼š
{param_analysis['param_docs']}

ğŸš¨ å¿…é¡»åœ¨å‡½æ•°å®šä¹‰åç«‹å³è°ƒç”¨ï¼š
__result__ = execute_task({param_analysis['call_args']})

é‡è¦ï¼šå‡½æ•°å®ç°åº”è¯¥çœŸæ­£ä½¿ç”¨è¿™äº›å‚æ•°æ¥å®Œæˆä»»åŠ¡ï¼Œè€Œä¸æ˜¯å¿½ç•¥å‚æ•°ã€‚
"""

    enhanced_prompt = f"""
{base_prompt}

{execution_guidance}
"""

    enhanced_prompt += f"\n\n{get_task_specific_format(task_type)}"

    return enhanced_prompt


def get_enhanced_aiforge_prompt_with_universal_validation(
    optimize_tokens: bool = True,
    task_type: Optional[str] = None,
    parameters: Optional[Dict[str, Any]] = None,
) -> str:
    """ç”Ÿæˆå¸¦é€šç”¨å‚æ•°éªŒè¯çº¦æŸçš„å¢å¼ºç³»ç»Ÿæç¤º"""

    base_prompt = get_base_aiforge_prompt(optimize_tokens)

    execution_guidance = ""
    if parameters:
        param_analysis = _analyze_parameters_for_execution(parameters)

        execution_guidance = f"""
## ğŸ”§ æ™ºèƒ½å‚æ•°åŒ–æ‰§è¡ŒæŒ‡å¯¼

åŸºäºä»»åŠ¡åˆ†æï¼Œç”Ÿæˆä»¥ä¸‹å‚æ•°åŒ–å‡½æ•°ï¼š

def execute_task({param_analysis['signature']}):
    '''
    {param_analysis['docstring']}
    '''
    # ğŸš¨ é€šç”¨å‚æ•°ä½¿ç”¨è¦æ±‚ï¼š
    # 1. æ¯ä¸ªå‚æ•°éƒ½å¿…é¡»åœ¨å‡½æ•°é€»è¾‘ä¸­è¢«å®é™…ä½¿ç”¨
    # 2. å‚æ•°å€¼å¿…é¡»å½±å“å‡½æ•°çš„æ‰§è¡Œç»“æœæˆ–è¿”å›å€¼
    # 3. ä¸å¾—ç¡¬ç¼–ç ä»»ä½•å¯ä»¥ä»å‚æ•°è·å–çš„å€¼
    # 4. å‚æ•°åº”è¯¥ç”¨äºæ§åˆ¶å‡½æ•°çš„è¡Œä¸ºã€æ•°æ®æºæˆ–è¾“å‡ºæ ¼å¼

    # å®ç°é€»è¾‘åº”è¯¥åŸºäºå‚æ•°çš„å®é™…å«ä¹‰å’Œä»»åŠ¡éœ€æ±‚
    return result_data

# å‚æ•°è¯´æ˜ï¼š
{param_analysis['param_docs']}

ğŸš¨ å¿…é¡»åœ¨å‡½æ•°å®šä¹‰åç«‹å³è°ƒç”¨ï¼š
__result__ = execute_task({param_analysis['call_args']})

## ğŸ“‹ é€šç”¨å‚æ•°ä½¿ç”¨éªŒè¯æ ‡å‡†ï¼š
1. å‚æ•°å¿…é¡»åœ¨å‡½æ•°ä½“å†…è¢«å¼•ç”¨å’Œä½¿ç”¨
2. å‚æ•°çš„å€¼å¿…é¡»å½±å“å‡½æ•°çš„æ‰§è¡Œè·¯å¾„æˆ–ç»“æœ
3. é¿å…ç¡¬ç¼–ç ä»»ä½•å¯ä»¥é€šè¿‡å‚æ•°ä¼ é€’çš„å€¼
4. å‚æ•°åº”è¯¥ç”¨äºï¼š
   - æ§åˆ¶å‡½æ•°è¡Œä¸ºï¼ˆæ¡ä»¶åˆ¤æ–­ã€å¾ªç¯æ§åˆ¶ï¼‰
   - ä½œä¸ºæ•°æ®æºï¼ˆAPIè°ƒç”¨ã€æ–‡ä»¶è·¯å¾„ã€æŸ¥è¯¢æ¡ä»¶ï¼‰
   - å½±å“è¾“å‡ºæ ¼å¼ï¼ˆæ ¼å¼åŒ–ã€è¿‡æ»¤ã€æ’åºï¼‰
   - é…ç½®æ‰§è¡Œå‚æ•°ï¼ˆè¶…æ—¶ã€é‡è¯•æ¬¡æ•°ã€ç²¾åº¦ï¼‰

## âŒ é€šç”¨ç¦æ­¢æ¨¡å¼ï¼š
- å®šä¹‰å‚æ•°ä½†ä¸åœ¨å‡½æ•°ä½“ä¸­ä½¿ç”¨
- å‚æ•°ä»…ç”¨äºå­—ç¬¦ä¸²æ‹¼æ¥æ˜¾ç¤ºï¼Œä¸å½±å“æ ¸å¿ƒé€»è¾‘
- ç¡¬ç¼–ç å€¼è€Œå¿½ç•¥ç›¸åº”å‚æ•°
- å‚æ•°ä»…ç”¨äºæ³¨é‡Šæˆ–æ—¥å¿—ï¼Œä¸å‚ä¸ä¸šåŠ¡é€»è¾‘
"""

    enhanced_prompt = f"""
{base_prompt}

{execution_guidance}
"""

    enhanced_prompt += f"\n\n{get_task_specific_format(task_type)}"

    return enhanced_prompt


def _analyze_parameters_for_execution(parameters: Dict[str, Any]) -> Dict[str, str]:
    """åˆ†æå‚æ•°ç»“æ„ï¼Œç”Ÿæˆæ‰§è¡ŒæŒ‡å¯¼"""
    param_names = []
    param_docs = []
    call_args = []

    for param_name, param_info in parameters.items():
        if isinstance(param_info, dict):
            value = param_info.get("value")
            param_type = param_info.get("type", "str")
            description = param_info.get("description", "")
            required = param_info.get("required", True)

            # æ„å»ºå‡½æ•°ç­¾å
            if required and value is not None:
                param_names.append(param_name)
                call_args.append(f'"{value}"' if param_type == "str" else str(value))
            elif not required:
                default_val = param_info.get("default", "None")
                param_names.append(f"{param_name}={default_val}")
                if value is not None:
                    call_args.append(f'"{value}"' if param_type == "str" else str(value))
                else:
                    if default_val is None:
                        call_args.append("None")
                    else:
                        call_args.append(str(default_val))

            # æ„å»ºå‚æ•°æ–‡æ¡£
            param_docs.append(f"- {param_name} ({param_type}): {description}")
        else:
            # ç®€å•å‚æ•°å¤„ç†
            param_names.append(param_name)
            call_args.append(f'"{param_info}"' if isinstance(param_info, str) else str(param_info))
            param_docs.append(f"- {param_name}: {param_info}")

    signature = ", ".join(param_names)
    call_signature = ", ".join(call_args)
    docstring = f"æ‰§è¡Œä»»åŠ¡ï¼Œä½¿ç”¨æä¾›çš„å‚æ•°: {', '.join(param_names)}"

    return {
        "signature": signature,
        "call_args": call_signature,
        "param_docs": "\n".join(param_docs),
        "docstring": docstring,
    }


def get_direct_response_prompt(action: str, standardized_instruction: Dict[str, Any]) -> str:
    """æ„å»ºç›´æ¥å“åº”ä¸“ç”¨æç¤ºè¯"""
    # åŸºç¡€æç¤ºè¯æ˜ å°„
    prompts = {
        "answer": "ä½ æ˜¯ä¸€ä¸ªçŸ¥è¯†åŠ©æ‰‹ï¼Œè¯·ç›´æ¥å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚è¦æ±‚å‡†ç¡®ã€ç®€æ´ã€æœ‰ç”¨ã€‚",
        "respond": "ä½ æ˜¯ä¸€ä¸ªçŸ¥è¯†åŠ©æ‰‹ï¼Œè¯·ç›´æ¥å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚è¦æ±‚å‡†ç¡®ã€ç®€æ´ã€æœ‰ç”¨ã€‚",
        "create": "ä½ æ˜¯ä¸€ä¸ªå†…å®¹åˆ›ä½œåŠ©æ‰‹ï¼Œè¯·æ ¹æ®ç”¨æˆ·è¦æ±‚åˆ›ä½œå†…å®¹ã€‚æ³¨æ„é£æ ¼å’Œæ ¼å¼è¦æ±‚ã€‚",
        "translate": "ä½ æ˜¯ä¸€ä¸ªç¿»è¯‘åŠ©æ‰‹ï¼Œè¯·å‡†ç¡®ç¿»è¯‘ç”¨æˆ·æä¾›çš„å†…å®¹ã€‚ä¿æŒåŸæ„å’Œè¯­è¨€é£æ ¼ã€‚",
        "summarize": "ä½ æ˜¯ä¸€ä¸ªæ–‡æœ¬åˆ†æåŠ©æ‰‹ï¼Œè¯·æ€»ç»“å’Œåˆ†æç”¨æˆ·æä¾›çš„æ–‡æœ¬å†…å®¹ã€‚",
        "suggest": "ä½ æ˜¯ä¸€ä¸ªå’¨è¯¢é¡¾é—®ï¼Œè¯·æ ¹æ®ç”¨æˆ·éœ€æ±‚æä¾›å»ºè®®å’Œæ„è§ã€‚",
    }

    base_prompt = prompts.get(action, "ä½ æ˜¯ä¸€ä¸ªAIåŠ©æ‰‹ï¼Œè¯·ç›´æ¥å“åº”ç”¨æˆ·çš„éœ€æ±‚ã€‚")

    # ä» standardized_instruction ä¸­æå–å¢å¼ºä¿¡æ¯
    target = standardized_instruction.get("target", "")
    output_format = standardized_instruction.get("output_format", "text")
    parameters = standardized_instruction.get("parameters", {})
    task_type = standardized_instruction.get("task_type", "")

    # æ„å»ºå¢å¼ºçš„æç¤ºè¯
    enhanced_sections = []

    # 1. ä»»åŠ¡ä¸Šä¸‹æ–‡å¢å¼º
    if target:
        enhanced_sections.append(f"ä»»åŠ¡ç›®æ ‡: {target}")

    # 2. è¾“å‡ºæ ¼å¼æŒ‡å¯¼
    format_guidance = {
        "text": "ä»¥çº¯æ–‡æœ¬å½¢å¼å›ç­”",
        "markdown": "ä½¿ç”¨Markdownæ ¼å¼ï¼ŒåŒ…å«é€‚å½“çš„æ ‡é¢˜ã€åˆ—è¡¨å’Œå¼ºè°ƒ",
        "structured_text": "ä½¿ç”¨ç»“æ„åŒ–çš„æ–‡æœ¬æ ¼å¼ï¼ŒåŒ…å«æ¸…æ™°çš„æ®µè½å’Œè¦ç‚¹",
    }

    if output_format in format_guidance:
        enhanced_sections.append(f"è¾“å‡ºè¦æ±‚: {format_guidance[output_format]}")

    # 3. å‚æ•°ä¸Šä¸‹æ–‡å¢å¼º
    if parameters:
        param_context = []
        for param_name, param_value in parameters.items():
            if param_value:
                param_context.append(f"- {param_name}: {param_value}")

        if param_context:
            enhanced_sections.append("ç›¸å…³å‚æ•°:\n" + "\n".join(param_context))

    # 4. ä»»åŠ¡ç±»å‹ç‰¹å®šæŒ‡å¯¼
    task_specific_guidance = {
        "direct_response": "ä¸“æ³¨äºç›´æ¥å›ç­”ï¼Œé¿å…å†—ä½™ä¿¡æ¯",
        "content_generation": "æ³¨é‡åˆ›æ„å’ŒåŸåˆ›æ€§",
        "data_process": "æä¾›æ¸…æ™°çš„åˆ†ææ€è·¯",
    }

    if task_type in task_specific_guidance:
        enhanced_sections.append(f"ç‰¹æ®Šè¦æ±‚: {task_specific_guidance[task_type]}")

    # ç»„è£…æœ€ç»ˆæç¤ºè¯
    enhanced_prompt = base_prompt

    if enhanced_sections:
        enhanced_prompt += "\n\n## ä»»åŠ¡è¯¦æƒ…\n" + "\n\n".join(enhanced_sections)

    enhanced_prompt += """

## é‡è¦é™åˆ¶
- ç›´æ¥æä¾›æœ€ç»ˆç­”æ¡ˆï¼Œä¸è¦ç”Ÿæˆä»£ç 
- å¦‚æœä»»åŠ¡éœ€è¦å®æ—¶æ•°æ®æˆ–æ–‡ä»¶æ“ä½œï¼Œè¯·è¯´æ˜æ— æ³•å®Œæˆ
- ä¿æŒå›ç­”çš„ä¸“ä¸šæ€§å’Œå‡†ç¡®æ€§
"""

    return enhanced_prompt


def get_enhanced_system_prompt_universal(
    standardized_instruction: Dict[str, Any], optimize_tokens=True, original_prompt: str = None
) -> str:
    """åŸºäºæ ‡å‡†åŒ–æŒ‡ä»¤æ„å»ºé€šç”¨å¢å¼ºç³»ç»Ÿæç¤ºè¯"""
    task_type = standardized_instruction.get("task_type", "general")

    # è·å–å‚æ•°ä¿¡æ¯
    parameters = standardized_instruction.get("required_parameters", {})
    if not parameters:
        parameters = standardized_instruction.get("parameters", {})

    # æœ€åçš„å›é€€ï¼šç¡®ä¿æœ‰åŸºæœ¬çš„æŒ‡ä»¤å‚æ•°
    if not parameters:
        parameters = {
            "instruction": {
                "value": standardized_instruction.get("target", ""),
                "type": "str",
                "description": "ç”¨æˆ·è¾“å…¥çš„æŒ‡ä»¤å†…å®¹",
                "required": True,
            }
        }

    # ä½¿ç”¨é€šç”¨å¢å¼ºç‰ˆæç¤ºè¯ç”Ÿæˆ
    enhanced_prompt = get_enhanced_aiforge_prompt_with_universal_validation(
        optimize_tokens=optimize_tokens,
        task_type=task_type,
        parameters=parameters,
    )

    if original_prompt:
        enhanced_prompt += f"\n\n# åŸå§‹æŒ‡ä»¤è¡¥å……\n{original_prompt}"

    return enhanced_prompt
