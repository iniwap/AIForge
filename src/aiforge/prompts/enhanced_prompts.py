from typing import Optional, Dict, Any


def get_task_specific_format(task_type: str) -> str:
    """è·å–ä»»åŠ¡ç‰¹å®šçš„è¾“å‡ºæ ¼å¼è¦æ±‚"""
    formats = {
        "web_search": """
# æœç´¢ä»»åŠ¡è¾“å‡ºæ ¼å¼
__result__ = {
    "data": {
        "results": [{"title": "...", "url": "...", "content": "..."}],
        "total_count": int,
        "query": "åŸå§‹æŸ¥è¯¢"
    },
    "status": "success",
    "summary": "æœç´¢å®Œæˆæè¿°",
    "metadata": {"timestamp": "...", "source": "æœç´¢å¼•æ“åç§°"}
}""",
        "data_analysis": """
# æ•°æ®åˆ†æä»»åŠ¡è¾“å‡ºæ ¼å¼
__result__ = {
    "data": {
        "analysis": {"key_findings": "...", "trends": "..."},
        "processed_data": processed_data,
        "summary": {"total_records": int, "key_metrics": {}}
    },
    "status": "success",
    "summary": "åˆ†æå®Œæˆæè¿°",
    "metadata": {"timestamp": "...", "data_source": "..."}
}""",
        "file_processing": """
# æ–‡ä»¶å¤„ç†ä»»åŠ¡è¾“å‡ºæ ¼å¼
__result__ = {
    "data": {
        "processed_files": [{"file": "...", "status": "success", "size": int}],
        "summary": {"total_files": int, "success_count": int, "error_count": int},
        "errors": [{"file": "...", "error": "..."}]
    },
    "status": "success",
    "summary": "æ–‡ä»¶å¤„ç†å®Œæˆæè¿°",
    "metadata": {"timestamp": "...", "operation": "..."}
}""",
        "api_call": """
# APIè°ƒç”¨ä»»åŠ¡è¾“å‡ºæ ¼å¼
__result__ = {
    "data": {
        "response_data": api_response,
        "status_code": int,
        "headers": response_headers,
        "summary": {"success": bool, "response_time": float}
    },
    "status": "success",
    "summary": "APIè°ƒç”¨å®Œæˆæè¿°",
    "metadata": {"endpoint": "...", "timestamp": "..."}
}""",
        "data_fetch": """
# æ•°æ®è·å–ä»»åŠ¡è¾“å‡ºæ ¼å¼
__result__ = {
    "data": {
        "content": "è·å–çš„æ•°æ®å†…å®¹",
        "source": "æ•°æ®æ¥æº",
        "additional_info": {}
    },
    "status": "success",
    "summary": "æ•°æ®è·å–å®Œæˆæè¿°",
    "metadata": {"timestamp": "...", "task_type": "data_fetch"}
}""",
        "web_request": """
# ç½‘é¡µè¯·æ±‚ä»»åŠ¡è¾“å‡ºæ ¼å¼
__result__ = {
    "data": {
        "content": "ç½‘é¡µå†…å®¹",
        "url": "è¯·æ±‚çš„URL",
        "status_code": int,
        "headers": {}
    },
    "status": "success",
    "summary": "ç½‘é¡µè¯·æ±‚å®Œæˆæè¿°",
    "metadata": {"timestamp": "...", "method": "GET/POST"}
}""",
        "automation": """
# è‡ªåŠ¨åŒ–ä»»åŠ¡è¾“å‡ºæ ¼å¼
__result__ = {
    "data": {
        "executed_steps": ["æ­¥éª¤1", "æ­¥éª¤2"],
        "results": {},
        "summary": {"total_steps": int, "success_steps": int}
    },
    "status": "success",
    "summary": "è‡ªåŠ¨åŒ–ä»»åŠ¡å®Œæˆæè¿°",
    "metadata": {"timestamp": "...", "workflow": "..."}
}""",
        "content_generation": """
# å†…å®¹ç”Ÿæˆä»»åŠ¡è¾“å‡ºæ ¼å¼
__result__ = {
    "data": {
        "generated_content": "ç”Ÿæˆçš„å†…å®¹",
        "content_type": "text/html/markdown",
        "word_count": int
    },
    "status": "success",
    "summary": "å†…å®¹ç”Ÿæˆå®Œæˆæè¿°",
    "metadata": {"timestamp": "...", "template": "..."}
}""",
    }

    return formats.get(
        task_type,
        """
# é€šç”¨ä»»åŠ¡è¾“å‡ºæ ¼å¼
__result__ = {
    "data": main_result,
    "status": "success/error",
    "summary": "ç»“æœæ‘˜è¦",
    "metadata": {"timestamp": "...", "task_type": "..."}
}""",
    )


def get_base_aiforge_prompt(optimize_tokens: bool = True) -> str:
    """ç”ŸæˆåŸºç¡€çš„AIForgeç³»ç»Ÿæç¤º"""
    # åŸºç¡€ä»£ç ç”Ÿæˆè§„åˆ™
    code_rule = """
- ç”Ÿæˆçš„ä»£ç å¿…é¡»èƒ½åœ¨æ ‡å‡† Python ç¯å¢ƒä¸­ç›´æ¥æ‰§è¡Œ
- ä½¿ç”¨æ ‡å‡† Markdown ä»£ç å—æ ¼å¼ï¼š```python ... ```ï¼Œä¸è¦è¾“å‡ºä»»ä½•è§£é‡Šæ€§æ–‡å­—
- ä½¿ç”¨é¢„è£…åº“ï¼šrequests, BeautifulSoup, pandas, numpy ç­‰
- å®ç°å®Œæ•´çš„é”™è¯¯å¤„ç†å’Œå¼‚å¸¸æ•è·
"""

    if optimize_tokens:
        code_rule += "\n- ç”Ÿæˆæç®€ä»£ç ï¼Œæ— æ³¨é‡Šï¼Œæ— ç©ºè¡Œ\n- ä½¿ç”¨æœ€çŸ­å˜é‡å(a,b,c,dç­‰)"

    # æ„å»ºåŸºç¡€ prompt
    base_prompt = f"""
# AIForgeï¼šPython ä»£ç ç”Ÿæˆå’Œæ‰§è¡ŒåŠ©æ‰‹

# ä»£ç ç”Ÿæˆè§„èŒƒ
{code_rule}

# æ‰§è¡Œè§„èŒƒ
æ‰§è¡Œä»£ç ï¼Œå¹¶å°†æ‰§è¡Œç»“æœèµ‹å€¼ç»™ __result__

"""
    return base_prompt


def get_enhanced_aiforge_prompt(
    optimize_tokens: bool = True,
    task_type: Optional[str] = None,
    parameters: Optional[Dict[str, Any]] = None,
) -> str:
    """ç”Ÿæˆå¢å¼ºçš„ç³»ç»Ÿæç¤º"""

    # è¾“å‡ºæ ¼å¼è¦æ±‚
    format_rules = """
## ğŸš¨ CRITICAL: è¾“å‡ºæ ¼å¼è¦æ±‚ ğŸš¨
__result__ å¿…é¡»æ˜¯å­—å…¸æ ¼å¼ï¼ŒåŒ…å«ï¼š
- "data": å®é™…æ•°æ®ï¼ˆæˆåŠŸæ—¶ï¼‰æˆ– nullï¼ˆå¤±è´¥æ—¶ï¼‰
- "status": "success" æˆ– "error"
- "summary": ç®€çŸ­æè¿°
- "metadata": åŒ…å«timestampç­‰ä¿¡æ¯"""

    # å‚æ•°åŒ–å’Œæ‰§è¡Œæ¨¡å¼æŒ‡å¯¼
    execution_guidance = ""
    if parameters:
        param_names = list(parameters.keys())
        param_descriptions = []
        for k, v in parameters.items():
            if isinstance(v, dict) and "description" in v:
                param_descriptions.append(
                    f"- {k}: {v['description']} (ç±»å‹: {v.get('type', 'str')})"
                )
            else:
                param_descriptions.append(f"- {k}: {v}")

        execution_guidance = f"""
## ğŸ”§ å‚æ•°åŒ–æ‰§è¡ŒæŒ‡å¯¼
è¯·ç”Ÿæˆä»¥ä¸‹å‚æ•°åŒ–å‡½æ•°å½¢å¼çš„ä»£ç ï¼š

def execute_task({', '.join(param_names)}):
    # æ‰§è¡Œå…·ä½“é€»è¾‘
    # ä»kwargsæå–å‚æ•°
    # ä¾‹å¦‚: location = kwargs.get('location', 'æ­å·')
    return result_data

å‚æ•°è¯´æ˜ï¼š
{chr(10).join(param_descriptions)}

ğŸš¨ å¿…é¡»å®šä¹‰å‡½æ•°åç«‹å³è°ƒç”¨å¹¶èµ‹å€¼ï¼š__result__ = execute_task(å‚æ•°...)"""

    # æ„å»ºåŸºç¡€ prompt
    enhanced_prompt = f"""
{get_base_aiforge_prompt(optimize_tokens)}

{format_rules}

{execution_guidance}
"""

    # ä»»åŠ¡ç‰¹å®šæ ¼å¼ï¼ˆä»…åœ¨éœ€è¦æ—¶æ·»åŠ ï¼‰
    if task_type and task_type != "general":
        enhanced_prompt += f"\n\n{get_task_specific_format(task_type)}"

    return enhanced_prompt
