import os
import pytest
import time
from aiforge import AIForgeCore


class TestAIForgeArchitecture:
    """AIForge æ¶æ„å…¨é¢æµ‹è¯•å¥—ä»¶"""

    @pytest.fixture(scope="class")
    def forge(self):
        """æµ‹è¯•ç”¨çš„ AIForge å®ä¾‹"""
        api_key = os.environ.get("OPENROUTER_API_KEY")
        if not api_key:
            pytest.skip("éœ€è¦è®¾ç½® OPENROUTER_API_KEY ç¯å¢ƒå˜é‡")
        return AIForgeCore(api_key=api_key)

    @pytest.fixture(scope="class")
    def forge_deepseek(self):
        """DeepSeek æä¾›å•†æµ‹è¯•å®ä¾‹"""
        api_key = os.environ.get("DEEPSEEK_API_KEY")
        if not api_key:
            pytest.skip("éœ€è¦è®¾ç½® DEEPSEEK_API_KEY ç¯å¢ƒå˜é‡")
        return AIForgeCore(api_key=api_key, provider="deepseek")


class TestInstructionAnalysis(TestAIForgeArchitecture):
    """æŒ‡ä»¤åˆ†æä¸åˆ†ç±»æµ‹è¯•"""

    @pytest.mark.parametrize(
        "instruction,expected_task_type",
        [
            ("è·å–æ­å·ä»Šå¤©çš„å¤©æ°”", "data_fetch"),
            ("åˆ†æè¿™ä¸ªCSVæ–‡ä»¶çš„æ•°æ®", "data_process"),
            ("å†™ä¸€é¦–å…³äºæ˜¥å¤©çš„è¯—", "content_generation"),
            ("ä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ ï¼Ÿ", "direct_response"),
            ("æ‰¹é‡å¤„ç†å›¾ç‰‡æ–‡ä»¶", "file_operation"),
            ("å®šæ—¶ç›‘æ§æœåŠ¡å™¨çŠ¶æ€", "automation"),
        ],
    )
    def test_local_analysis_task_types(self, forge, instruction, expected_task_type):
        """æµ‹è¯•æœ¬åœ°åˆ†æçš„ä»»åŠ¡ç±»å‹è¯†åˆ«"""
        # è¿™é‡Œæµ‹è¯•æŒ‡ä»¤åˆ†æå™¨çš„æœ¬åœ°åˆ†æèƒ½åŠ›
        if hasattr(forge, "instruction_analyzer"):
            result = forge.instruction_analyzer.local_analyze_instruction(instruction)
            # éªŒè¯ä»»åŠ¡ç±»å‹è¯†åˆ«æ˜¯å¦æ­£ç¡®
            assert (
                result.get("task_type") == expected_task_type or result.get("confidence", 0) < 0.6
            )

    @pytest.mark.parametrize(
        "ambiguous_instruction", ["å¸®æˆ‘æå®šè¿™ä¸ªé—®é¢˜", "å¤„ç†ä¸€ä¸‹æ•°æ®åº“çš„äº‹æƒ…", "ä¼˜åŒ–ç³»ç»Ÿæ€§èƒ½"]
    )
    def test_ai_enhanced_analysis(self, forge, ambiguous_instruction):
        """æµ‹è¯•AIå¢å¼ºåˆ†æå¤„ç†æ¨¡ç³ŠæŒ‡ä»¤"""
        result = forge(ambiguous_instruction)
        # æ¨¡ç³ŠæŒ‡ä»¤åº”è¯¥èƒ½å¤Ÿé€šè¿‡AIåˆ†æå¾—åˆ°ç»“æœ
        assert result is not None
        assert isinstance(result, dict)


class TestExecutionModes(TestAIForgeArchitecture):
    """æ‰§è¡Œæ¨¡å¼è·¯å¾„æµ‹è¯•"""

    @pytest.mark.parametrize(
        "direct_instruction",
        [
            "è§£é‡Šä»€ä¹ˆæ˜¯æ·±åº¦å­¦ä¹ ",
            "ç¿»è¯‘è¿™å¥è¯ï¼šHello World",
            "æ€»ç»“äººå·¥æ™ºèƒ½çš„å‘å±•å†å²",
            "å†™ä¸€é¦–ä¸ƒè¨€ç»å¥",
        ],
    )
    def test_direct_response_mode(self, forge, direct_instruction):
        """æµ‹è¯•ç›´æ¥å“åº”æ¨¡å¼"""
        result = forge(direct_instruction)
        assert result is not None
        assert result.get("status") == "success"
        # ç›´æ¥å“åº”åº”è¯¥åŒ…å«ç”Ÿæˆçš„å†…å®¹
        assert "data" in result

    @pytest.mark.parametrize(
        "code_instruction",
        [
            "è·å–åŒ—äº¬ä»Šå¤©çš„è‚¡ä»·ä¿¡æ¯",
            "åˆ†æsales.csvæ–‡ä»¶ä¸­çš„é”€å”®è¶‹åŠ¿",
            "çˆ¬å–æ–°æµªæ–°é—»é¦–é¡µçš„æ ‡é¢˜",
            "è®¡ç®—æ–æ³¢é‚£å¥‘æ•°åˆ—å‰20é¡¹",
        ],
    )
    def test_code_generation_mode(self, forge, code_instruction):
        """æµ‹è¯•ä»£ç ç”Ÿæˆæ¨¡å¼"""
        result = forge(code_instruction)
        assert result is not None
        # ä»£ç ç”Ÿæˆæ¨¡å¼åº”è¯¥è¿”å›æ‰§è¡Œç»“æœ
        assert isinstance(result, dict)


class TestCachingSystem(TestAIForgeArchitecture):
    """ç¼“å­˜ç³»ç»Ÿæµ‹è¯•"""

    def test_cache_hit_weather_queries(self, forge):
        """æµ‹è¯•å¤©æ°”æŸ¥è¯¢çš„ç¼“å­˜å‘½ä¸­"""
        # ç¬¬ä¸€æ¬¡æ‰§è¡Œï¼Œå»ºç«‹ç¼“å­˜
        result1 = forge("è·å–ä¸Šæµ·ä»Šå¤©çš„å¤©æ°”")
        assert result1 is not None

        # ç­‰å¾…ç¼“å­˜ä¿å­˜å®Œæˆ
        time.sleep(1)

        # ç¬¬äºŒæ¬¡æ‰§è¡Œï¼Œåº”è¯¥å‘½ä¸­ç¼“å­˜
        result2 = forge("è·å–æ·±åœ³ä»Šå¤©çš„å¤©æ°”")
        assert result2 is not None

        # éªŒè¯ä¸¤æ¬¡éƒ½æˆåŠŸæ‰§è¡Œ
        assert result1.get("status") == "success"
        assert result2.get("status") == "success"

    @pytest.mark.parametrize(
        "first_instruction,second_instruction,should_match",
        [
            ("è·å–å¤©æ°”ä¿¡æ¯", "æŸ¥è¯¢ä»Šå¤©å¤©æ°”", True),
            ("ä¸‹è½½æ–°é—»æ•°æ®", "çˆ¬å–æ–°é—»å†…å®¹", True),
            ("å¤©æ°”æŸ¥è¯¢", "æ–°é—»è·å–", False),
        ],
    )
    def test_semantic_matching(self, forge, first_instruction, second_instruction, should_match):
        """æµ‹è¯•è¯­ä¹‰åŒ¹é…"""
        # æ‰§è¡Œç¬¬ä¸€ä¸ªæŒ‡ä»¤å»ºç«‹ç¼“å­˜
        result1 = forge(first_instruction)
        assert result1 is not None

        time.sleep(1)

        # æ‰§è¡Œç¬¬äºŒä¸ªæŒ‡ä»¤æµ‹è¯•è¯­ä¹‰åŒ¹é…
        result2 = forge(second_instruction)
        assert result2 is not None

        # æ ¹æ®é¢„æœŸéªŒè¯æ˜¯å¦åº”è¯¥åŒ¹é…
        if should_match:
            # å¦‚æœåº”è¯¥åŒ¹é…ï¼Œä¸¤ä¸ªç»“æœçš„ç»“æ„åº”è¯¥ç›¸ä¼¼
            assert result1.get("metadata", {}).get("task_type") == result2.get("metadata", {}).get(
                "task_type"
            )


class TestMultiRoundExecution(TestAIForgeArchitecture):
    """å¤šè½®æ‰§è¡Œä¸é”™è¯¯æ¢å¤æµ‹è¯•"""

    def test_complex_task_execution(self, forge):
        """æµ‹è¯•å¤æ‚ä»»åŠ¡çš„å¤šè½®æ‰§è¡Œ"""
        complex_instruction = "åˆ†æä¸€ä¸ªåŒ…å«ç”¨æˆ·è¡Œä¸ºæ•°æ®çš„JSONæ–‡ä»¶å¹¶ç”Ÿæˆç»Ÿè®¡æŠ¥å‘Š"
        result = forge(complex_instruction)

        # å¤æ‚ä»»åŠ¡åº”è¯¥èƒ½å¤Ÿå®Œæˆæˆ–ç»™å‡ºåˆç†çš„é”™è¯¯ä¿¡æ¯
        assert result is not None
        assert isinstance(result, dict)

    def test_error_recovery(self, forge):
        """æµ‹è¯•é”™è¯¯æ¢å¤æœºåˆ¶"""
        # æ•…æ„ä½¿ç”¨å¯èƒ½å¤±è´¥çš„æŒ‡ä»¤
        error_prone_instruction = "è®¿é—®ä¸å­˜åœ¨çš„APIæ¥å£http://nonexistent.api/data"
        result = forge(error_prone_instruction)

        # ç³»ç»Ÿåº”è¯¥èƒ½å¤Ÿå¤„ç†é”™è¯¯å¹¶è¿”å›ç»“æœ
        assert result is not None
        assert isinstance(result, dict)


class TestParameterizedExecution(TestAIForgeArchitecture):
    """å‚æ•°åŒ–æ‰§è¡Œæµ‹è¯•"""

    @pytest.mark.parametrize(
        "parameterized_instruction",
        ["è·å–åŒ—äº¬åœ¨2024-01-01çš„å¤©æ°”æƒ…å†µ", "åˆ†ædata.csvæ–‡ä»¶çš„é”€å”®æ•°æ®", "ç”Ÿæˆç§‘æŠ€ä¸»é¢˜çš„500å­—æ–‡ç« "],
    )
    def test_parameter_extraction(self, forge, parameterized_instruction):
        """æµ‹è¯•å‚æ•°æå–ä¸ä¼ é€’"""
        result = forge(parameterized_instruction)
        assert result is not None
        assert isinstance(result, dict)

        # éªŒè¯å‚æ•°åŒ–ä»»åŠ¡èƒ½å¤Ÿæ­£ç¡®å¤„ç†
        if result.get("status") == "success":
            assert "data" in result


class TestProviderManagement(TestAIForgeArchitecture):
    """LLMæä¾›å•†ç®¡ç†æµ‹è¯•"""

    def test_provider_switching(self, forge):
        """æµ‹è¯•æä¾›å•†åˆ‡æ¢"""
        # è·å–å½“å‰å¯ç”¨çš„æä¾›å•†
        providers = forge.list_providers()
        assert isinstance(providers, (list, dict))

        # æµ‹è¯•åˆ‡æ¢åˆ°ä¸åŒæä¾›å•†
        if "deepseek" in str(providers):
            success = forge.switch_provider("deepseek")
            assert isinstance(success, bool)

    def test_multiple_providers(self, forge, forge_deepseek):
        """æµ‹è¯•å¤šä¸ªæä¾›å•†çš„åŠŸèƒ½"""
        simple_task = "è®¡ç®—1+1ç­‰äºå¤šå°‘"

        # æµ‹è¯•é»˜è®¤æä¾›å•†
        result1 = forge(simple_task)
        assert result1 is not None

        # æµ‹è¯•DeepSeekæä¾›å•†
        result2 = forge_deepseek(simple_task)
        assert result2 is not None


class TestInputAdaptation(TestAIForgeArchitecture):
    """è¾“å…¥é€‚é…æµ‹è¯•"""

    @pytest.mark.parametrize(
        "input_data,source",
        [
            ({"text": "åˆ†ææ•°æ®", "context": "web_interface"}, "web"),
            ({"instruction": "è·å–ä¿¡æ¯", "source": "api_call"}, "api"),
            ("å‘½ä»¤è¡Œç›´æ¥è¾“å…¥", "cli"),
        ],
    )
    def test_multi_source_input(self, forge, input_data, source):
        """æµ‹è¯•å¤šæºè¾“å…¥é€‚é…"""
        try:
            result = forge.run_with_input_adaptation(input_data, source)
            # è¾“å…¥é€‚é…åº”è¯¥èƒ½å¤Ÿå¤„ç†ä¸åŒæ ¼å¼çš„è¾“å…¥
            assert result is not None or True  # å…è®¸æŸäº›è¾“å…¥æ ¼å¼ä¸è¢«æ”¯æŒ
        except Exception as e:
            # è®°å½•ä½†ä¸å¤±è´¥ï¼Œå› ä¸ºæŸäº›è¾“å…¥æ ¼å¼å¯èƒ½ä¸è¢«æ”¯æŒ
            print(f"Input adaptation failed for {source}: {e}")


class TestBoundaryConditions(TestAIForgeArchitecture):
    """è¾¹ç•Œæ¡ä»¶ä¸å¼‚å¸¸æµ‹è¯•"""

    @pytest.mark.parametrize(
        "edge_case",
        [
            "",  # ç©ºæŒ‡ä»¤
            "a" * 100,  # é•¿æŒ‡ä»¤ï¼ˆå‡å°‘é•¿åº¦é¿å…è¶…æ—¶ï¼‰
            "ğŸ‰ğŸš€ğŸ’»",  # ç‰¹æ®Šå­—ç¬¦
        ],
    )
    def test_edge_cases(self, forge, edge_case):
        """æµ‹è¯•è¾¹ç•Œæ¡ä»¶"""
        try:
            result = forge(edge_case)
            # è¾¹ç•Œæ¡ä»¶åº”è¯¥è¢«ä¼˜é›…å¤„ç†
            if result is not None:
                assert isinstance(result, dict)
        except Exception as e:
            # æŸäº›è¾¹ç•Œæ¡ä»¶å¯èƒ½ä¼šæŠ›å‡ºå¼‚å¸¸ï¼Œè¿™æ˜¯å¯ä»¥æ¥å—çš„
            print(f"Edge case handled with exception: {e}")

    def test_none_input(self, forge):
        """æµ‹è¯•Noneè¾“å…¥"""
        with pytest.raises((ValueError, TypeError, AttributeError)):
            forge(None)

    def test_invalid_format_input(self, forge):
        """æµ‹è¯•æ— æ•ˆæ ¼å¼è¾“å…¥"""
        with pytest.raises((ValueError, TypeError, AttributeError)):
            forge({"invalid": "format"})


class TestSystemIntegration(TestAIForgeArchitecture):
    """ç³»ç»Ÿé›†æˆæµ‹è¯•"""

    def test_end_to_end_workflow(self, forge):
        """æµ‹è¯•ç«¯åˆ°ç«¯å·¥ä½œæµ"""
        # æµ‹è¯•å®Œæ•´çš„å·¥ä½œæµç¨‹
        instructions = [
            "ä»€ä¹ˆæ˜¯äººå·¥æ™ºèƒ½ï¼Ÿ",  # ç›´æ¥å“åº”
            "è·å–ä»Šå¤©çš„å¤©æ°”ä¿¡æ¯",  # æ•°æ®è·å–
            "å†™ä¸€é¦–å…³äºæ˜¥å¤©çš„è¯—",  # å†…å®¹ç”Ÿæˆ
        ]

        results = []
        for instruction in instructions:
            result = forge(instruction)
            results.append(result)
            assert result is not None
            time.sleep(0.5)  # é¿å…è¯·æ±‚è¿‡å¿«

        # éªŒè¯æ‰€æœ‰ä»»åŠ¡éƒ½æˆåŠŸå®Œæˆ
        assert len(results) == len(instructions)
        assert all(r is not None for r in results)

    def test_cache_persistence(self, forge):
        """æµ‹è¯•ç¼“å­˜æŒä¹…åŒ–"""
        # æ‰§è¡Œä¸€ä¸ªä»»åŠ¡å»ºç«‹ç¼“å­˜
        result1 = forge("è·å–å¤©æ°”é¢„æŠ¥")
        assert result1 is not None

        time.sleep(1)

        # å†æ¬¡æ‰§è¡Œç›¸ä¼¼ä»»åŠ¡ï¼Œåº”è¯¥èƒ½å¤Ÿåˆ©ç”¨ç¼“å­˜
        result2 = forge("æŸ¥è¯¢å¤©æ°”æƒ…å†µ")
        assert result2 is not None

        # éªŒè¯ç¼“å­˜ç³»ç»Ÿæ­£å¸¸å·¥ä½œ
        if hasattr(forge, "code_cache") and forge.code_cache:
            modules = forge.code_cache.get_all_modules()
            assert len(modules) > 0


# æ€§èƒ½æµ‹è¯•
class TestPerformance(TestAIForgeArchitecture):
    """æ€§èƒ½æµ‹è¯•"""

    def test_response_time(self, forge):
        """æµ‹è¯•å“åº”æ—¶é—´"""
        start_time = time.time()
        result = forge("1+1ç­‰äºå¤šå°‘ï¼Ÿ")
        end_time = time.time()

        response_time = end_time - start_time
        assert result is not None
        # ç®€å•ä»»åŠ¡åº”è¯¥åœ¨åˆç†æ—¶é—´å†…å®Œæˆï¼ˆ30ç§’ï¼‰
        assert response_time < 30

    def test_concurrent_requests(self, forge):
        """æµ‹è¯•å¹¶å‘è¯·æ±‚å¤„ç†"""
        import concurrent.futures

        def execute_task(instruction):
            return forge(f"è®¡ç®—{instruction}")

        instructions = ["1+1", "2+2", "3+3"]

        with concurrent.futures.ThreadPoolExecutor(max_workers=3) as executor:
            futures = [executor.submit(execute_task, inst) for inst in instructions]
            results = [future.result() for future in concurrent.futures.as_completed(futures)]

        # æ‰€æœ‰å¹¶å‘ä»»åŠ¡éƒ½åº”è¯¥æˆåŠŸå®Œæˆ
        assert len(results) == len(instructions)
        assert all(r is not None for r in results)


if __name__ == "__main__":
    # è¿è¡Œæµ‹è¯•çš„ç¤ºä¾‹å‘½ä»¤
    pytest.main(
        [
            __file__,
            "-v",  # è¯¦ç»†è¾“å‡º
            "--tb=short",  # ç®€çŸ­çš„é”™è¯¯è¿½è¸ª
            "-x",  # é‡åˆ°ç¬¬ä¸€ä¸ªå¤±è´¥å°±åœæ­¢
        ]
    )

r"""
# è¿è¡Œæ‰€æœ‰æµ‹è¯•  
pytest tests/test_comprehensive_architecture.py -v  
  
# è¿è¡Œç‰¹å®šæµ‹è¯•ç±»  
pytest tests/test_comprehensive_architecture.py::TestInstructionAnalysis -v  
  
# è¿è¡Œç‰¹å®šæµ‹è¯•æ–¹æ³•  
pytest tests/test_comprehensive_architecture.py::TestCachingSystem::test_cache_hit_weather_queries -v  
  
# å¹¶è¡Œè¿è¡Œæµ‹è¯•ï¼ˆéœ€è¦å®‰è£…pytest-xdistï¼‰  
pytest tests/test_comprehensive_architecture.py -n auto  

# ç”Ÿæˆè¦†ç›–ç‡æŠ¥å‘Šï¼ˆéœ€è¦å®‰è£…pytest-covï¼‰  
pip install pytest-cov  
  
# è¿è¡Œæµ‹è¯•å¹¶ç”Ÿæˆè¦†ç›–ç‡æŠ¥å‘Š  
pytest tests/test_comprehensive_architecture.py --cov=src/aiforge --cov-report=html --cov-report=term  
  
# ç”Ÿæˆè¯¦ç»†çš„è¦†ç›–ç‡æŠ¥å‘Š  
pytest tests/test_comprehensive_architecture.py \  
    --cov=src/aiforge \  
    --cov-report=html:htmlcov 
    --cov-report=term-missing \  
    --cov-report=xml  
  
# åªæ˜¾ç¤ºæœªè¦†ç›–çš„è¡Œ  
pytest tests/test_comprehensive_architecture.py --cov=src/aiforge --cov-report=term-missing  
  
# è®¾ç½®è¦†ç›–ç‡é˜ˆå€¼ï¼ˆä¾‹å¦‚80%ï¼‰  
pytest tests/test_comprehensive_architecture.py --cov=src/aiforge --cov-fail-under=80



è¦†ç›–ç‡é…ç½®æ–‡ä»¶ 
æ‚¨å¯ä»¥åˆ›å»º .coveragerc æ–‡ä»¶æ¥é…ç½®è¦†ç›–ç‡è®¾ç½®ï¼š

[run]  
source = src/aiforge  
omit =   
    */tests/*  
    */test_*  
    */__pycache__/*  
    */venv/*  
    */env/*  
  
[report]  
exclude_lines =  
    pragma: no cover  
    def __repr__  
    raise AssertionError  
    raise NotImplementedError  
    if __name__ == .__main__.:  
  
[html]  
directory = htmlcov
é›†æˆåˆ°CI/CD 
# GitHub Actions ç¤ºä¾‹  
- name: Run tests with coverage  
  run: |  
    pytest tests/test_comprehensive_architecture.py \  
      --cov=src/aiforge \  
      --cov-report=xml \  
      --cov-report=term  
  
- name: Upload coverage to Codecov  
  uses: codecov/codecov-action@v3  
  with:  
    file: ./coverage.xml
    
"""
